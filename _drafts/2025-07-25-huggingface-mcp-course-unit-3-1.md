---
title: "Build a Pull Request Agent on the Hugging Face Hub"
date: "2025-07-25 23:02:13 +0900"
last_modified_at: "2025-07-25 23:02:13 +0900"
---

## Build a Pull Request Agent on the Hugging Face Hub
1.  **Hugging Face Hubにおけるプルリクエストエージェントの構築**: 本プロジェクトは、Hugging Face Hubのモデルリポジトリにおいて、議論やコメントに基づいて自動的にタグ付けを行うプルリクエストエージェントを構築することを目的としています。これは、MCP（Model Collaboration Platform）をWebhookリスナーや自動化されたワークフローと統合する現実世界のアプリケーションの例です。エージェントは、モデル作成者が手動でタグ付けする手間を省き、すぐに使えるプルリクエストを提供することを目指します。

2.  **MCPサーバーの役割と機能**: プロジェクトの中核をなすのはFastMCPベースのサーバーであり、これには以下の機能が含まれます。モデルリポジトリから現在のタグを読み取る機能、Hubへのプルリクエストを通じて新しいタグを追加する機能、エラー処理とバリデーションの機能です。MCPサーバーは、GradioアプリやFastAPIアプリを用いてテストされます。

3.  **Webhook統合によるリアルタイムな応答**: このエージェントは、Hugging Faceのディスカッションボットで使用されているものと同じWebhookインフラストラクチャを利用します。Webhookは、ユーザーがモデルリポジトリのディスカッションにコメントを作成すると、Hugging FaceがPOSTリクエストを特定のエンドポイントに送信することで、リアルタイムな応答を可能にします。エージェントはWebhookのシグネチャを検証し、コメントを分析してタグの提案を抽出し、関連するタグが見つかった場合はプルリクエストを自動的に作成します。

4.  **エージェントの機能**: エージェントは、ディスカッションの内容を分析し、明示的なタグのメンション（例：`tag: pytorch`、`#transformers`）を抽出したり、自然言語から暗黙的なタグを認識したりします。また、既知の機械学習/AIカテゴリに対してタグを検証し、適切なプルリクエストの説明を生成します。

5.  **デプロイメントと本番環境**: このプロジェクトでは、Hugging Face Spacesへのコンテナ化されたデプロイメント、シークレットのための環境変数管理、Webhook応答のためのバックグラウンドタスク処理、およびテストとモニタリングのためのGradioインターフェースが含まれます。必要なファイルには、MCPサーバー（`mcp_server.py`）、Webhookリスナーとエージェント（`app.py`）、依存関係ファイル（`requirements.txt`）、プロジェクト設定ファイル（`pyproject.toml`）、Dockerfile、設定テンプレート（`env.example`）、および開発/テスト用のユーティリティスクリプト（`cleanup.py`）が含まれます。

## Setting up the Project
1.  **プロジェクトのセットアップと依存関係の管理:** このドキュメントは、Pull Request Agent (PRエージェント) の開発環境を構築する手順を説明しています。`uv`というモダンなPythonツールを用いて依存関係を管理し、必要な構成ファイルを作成します。特に、`uv`のインストール方法と、`pyproject.toml`ファイルの作成に焦点を当てています。

2.  **プロジェクトの構造:**  `hf-pr-agent`ディレクトリ内に、`mcp_server.py` (MCPサーバのコード), `app.py` (アプリケーションのエントリーポイント), `requirements.txt` (依存関係リスト), `pyproject.toml` (プロジェクト設定), `env.example` (環境変数のテンプレート), `cleanup.py` (クリーンアップスクリプト) などのファイルが含まれることを示しています。

3.  **`pyproject.toml`ファイルの設定:**  `pyproject.toml` ファイルには、プロジェクトの名前、バージョン、説明、依存関係などが定義されています。具体的な依存関係として、`fastapi`, `uvicorn`, `gradio`, `huggingface-hub[mcp]`, `pydantic`, `python-multipart`, `requests`, `python-dotenv`, `fastmcp`などがリストされています。 `hatchling`を用いたビルド設定も含まれています。

4.  **`requirements.txt`ファイル:** `requirements.txt`ファイルは`pyproject.toml`との互換性を保つために用いられます。仮想環境の作成(`uv venv`)と依存関係のインストール(`uv pip install`)の手順が示されています。

5.  **環境変数の設定:**  `env.example`ファイルは、必要な環境変数をドキュメント化するために使用されます。 `HF_TOKEN` (Hugging Face APIトークン), `WEBHOOK_SECRET` (Webhookシークレット), `HF_MODEL` (モデル名), `HF_PROVIDER` (プロバイダ)を設定する必要があることが示されています。 Hugging Face APIトークンの取得方法と、Webhookシークレットの生成方法 ( `python -c "import secrets; print(secrets.token_hex(32))"` ) が記述されています。

6.  **.envファイルの重要性:** 生成したWebhookシークレットを`.env`ファイルに設定し、`.gitignore`ファイルに追加することで、機密情報の漏洩を防ぐことが強調されています。

7.  **今後のステップ:**  MCPサーバーの作成、Webhookリスナーの構築、エージェントの統合、テストとデプロイなど、今後の開発ステップが示されています。 特に、Hugging Face Hubとのインタラクションを処理するMCPサーバーの作成が次の段階として説明されています。


## Creating the MCP Server
1.  **MCPサーバーのアーキテクチャと目的:** MCP (Model Card Processor) サーバーは、プルリクエストエージェントの中核であり、Hugging Face Hubとのやり取りを抽象化し、モデルリポジトリのタグの読み取りと更新を行うためのツールを提供します。具体的には、`get_current_tags`（現在のタグを取得）と`add_new_tag`（プルリクエストを通じて新しいタグを追加）の2つの主要なツールを提供し、Hub APIとの複雑なやり取りを簡素化します。

2.  **必要なインポートと設定:** `fastmcp`、`huggingface_hub`、`dotenv`などのライブラリをインポートし、Hugging Faceトークンを環境変数から読み込みます。トークンが存在する場合は認証されたAPIクライアントを作成し、FastMCPサーバーを初期化します。トークンがない場合でもサーバーが起動できるように、条件付きでAPIクライアントを作成します。

3.  **`get_current_tags`ツールの実装:** このツールは、指定されたモデルリポジトリから既存のタグを取得します。APIクライアントが存在するかを最初に検証し、存在しない場合はエラーを返します。APIを使用してモデル情報を取得し、タグを抽出してJSON形式で返します。エラーが発生した場合は、詳細なエラーメッセージを含むJSONを返します。MCPサーバーとクライアント間の通信には、JSON文字列を使用することが重要です。

4.  **`add_new_tag`ツールの実装 (タグの存在確認とモデルカードの処理):** `add_new_tag`ツールは、プルリクエストを通じて新しいタグをリポジトリに追加します。最初にAPIクライアントの存在を検証し、次にリポジトリの現在の状態を取得して、新しいタグがすでに存在するかどうかを確認します。タグが既に存在する場合は、既存のタグであることを示すメッセージを返します。タグが存在しない場合は、既存のモデルカードをロードするか、存在しない場合は新しいモデルカードを作成し、タグリストを更新します。

5.  **`add_new_tag`ツールの実装 (プルリクエストの作成):** 更新されたタグリストを使用して、モデルカードを更新し、プルリクエストを作成します。プルリクエストのタイトルと説明は詳細に記述され、変更内容と理由を明確に伝えます。`create_commit`関数を使用して、更新されたREADME.mdファイルを含むコミットを作成し、自動的にプルリクエストをオープンします。エラー処理は徹底的に行われ、エラーの種類とトレースバック情報が含まれます。

6.  **ロギングとエラー処理の重要性:** 広範なロギングは、サーバーのデバッグと監視に不可欠です。特に、自動化されたアプリケーションでは、リアルタイムでログを確認できないため、詳細なログが重要になります。エラー処理には、完全なトレースバックを含めることで、問題の特定と解決を容易にします。

7.  **無限ループの防止:** `create_commit`関数は、コミットごとにプルリクエストを作成するため、マージされていないプルリクエストが存在する場合、無限ループが発生する可能性があります。この問題を防止するためのチェックが実装されていますが、注意が必要です。

8.  **次のステップ:** MCPサーバーの実装が完了したら、MCPクライアントの作成、Webhook処理の実装、エージェントロジックの統合、およびシステム全体のテストを行う必要があります。MCPサーバーは、メインアプリケーションとは別のプロセスとして実行され、エラー処理の向上と複数のクライアントやアプリケーションによる再利用を可能にします。

## MCP Client
1.  **MCPクライアントの概要：** MCPクライアントは、WebhookハンドラーとMCPサーバー間の橋渡し役として機能し、エージェントがHubのタグ付け機能を使用できるようにします。教育目的のため、MCPサーバーとクライアントは同じリポジトリで構築されますが、実際のアプリケーションでは、それぞれ別のリポジトリで管理される可能性があります。APIとGradioアプリを構築し、APIはMCPサーバーとWebhookリスナーのテストに使用し、GradioアプリはシミュレートされたWebhookイベントでMCPクライアントをテストします。

2.  **MCPクライアントのアーキテクチャとAgentクラスの利用：** MCPクライアントは、FastAPIアプリケーション(app.py)に統合され、MCPサーバーへの接続を管理し、ツール実行のためのシームレスなインターフェースを提供します。`huggingface_hub`の`Agent`クラスを使用し、これは言語モデル機能とMCPツールの統合を単一のコンポーネントで提供します。この`Agent`クラスにはMCPサポートが組み込まれています。

3.  **Agentインスタンスの構成と管理：** グローバル変数`agent_instance`を使用して、Agentインスタンスを一度だけ作成し、複数のリクエストで再利用します。`get_agent()`関数は、既存のインスタンスがない場合にのみ新しいAgentインスタンスを作成し、`HF_TOKEN`、モデル名(`HF_MODEL`)、プロバイダー(`DEFAULT_PROVIDER`)などの設定を適用します。`Agent`のコンフィグレーションでは、`model`, `provider`, `api_key`等の引数に加えて、`servers`でMCPサーバーへの接続方法を指定します。`stdio`接続タイプは、MCPサーバーをサブプロセスとして起動し、標準入出力で通信するために使用されます。`agent_instance.load_tools()`を呼び出すことで、MCPサーバーから利用可能なツールを検出し、エージェントの推論エンジンからアクセスできるようにします。

4.  **ツールの自動検出と利用：** Agentは、MCPツールを自動的に検出し、利用できます。例えば、`get_current_tags(repo_id: str)`は既存のリポジトリのタグを取得し、`add_new_tag(repo_id: str, new_tag: str)`はプルリクエストを通じて新しいタグを追加します。Agentはプロンプトに基づいて、ツールをいつ、どのように使用するかを推論します。

5.  **ツールの実行例：** Agentに自然言語の指示（例: "microsoft/DialoGPT-medium の現在のタグを確認し、'conversational-ai' タグがまだ存在しない場合は追加する"）を与えると、Agentはまず`get_current_tags`を呼び出して既存のタグを確認し、`conversational-ai`が存在しない場合に`add_new_tag`を呼び出してタグを追加し、最後に実行した内容の概要を提供します。

6.  **Webhook処理との統合：** `process_webhook_comment`関数は、Webhookイベントを処理し、MCPエージェントを使用してタグを検出および追加します。コメントの内容とディスカッションのタイトルからタグを抽出し、重複を排除します。次に、各タグに対してAgentに明確なプロンプトを与え、Agentが現在のタグを確認し、新しいタグと比較し、必要に応じてプルリクエストを作成し、アクションの概要を返します。

7.  **タグ抽出ロジック：** `extract_tags_from_text`関数は、テキストからタグを抽出するために、明示的なパターン（例: "tags: pytorch, transformers"）、ハッシュタグ（例: "#pytorch #nlp"）、自然な言及（例: "This transformers model does text-generation"）の複数の戦略を使用します。`RECOGNIZED_TAGS`リストを使用して、関連性の高いML/AIタグに焦点を当て、不適切なタグがリポジトリに追加されるのを防ぎます。

8.  **パフォーマンスに関する考慮事項：** 本番環境のMCPクライアントでは、パフォーマンスが重要です。AgentのSingletonパターンを使用して、MCPサーバーの起動オーバーヘッド、ツールのロード遅延、接続確立コストを回避します。すべてのMCP操作は非同期で実行され、複数のWebhookリクエストを同時に処理し、FastAPIのメインスレッドをブロックしないようにします。`BackgroundTasks`を使用して、Webhookのレスポンスが高速（1秒以内）になるようにし、複雑なタグ処理をバックグラウンドで非同期的に実行します。

9.  **次のステップ：** MCPクライアントの実装が完了したら、Webhookリスナーを実装し、Webhook、クライアント、サーバーを完全なシステムに統合し、開発と監視のためのGradioインターフェースを追加し、完全なシステムをデプロイしてテストします。`huggingface_hub`の`Agent`クラスは、MCPツールの統合と言語モデルの推論の両方を提供し、PRエージェントのようなインテリジェントな自動化ワークフローの構築に最適です。

