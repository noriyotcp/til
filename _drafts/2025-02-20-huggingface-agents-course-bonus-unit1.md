---
title: "Hugging Face AI Agent Course - Bonus Unit1. Fine-tuning an LLM for function-calling"
date: "2025-02-20 23:01:17 +0900"
last_modified_at: "2025-02-20 23:01:17 +0900"
---

## Introduction
### What you'll learn

#### 要約
役立つまとめを提供しますので、内容のハイライトを簡単にまとめてください。

「ファインチューニング」とは、特定のタスクに対して LLM をカスタマイズするプロセスです。

LLM の関数呼び出しを微調整することで、以下が可能になります。

* モデルがアクションを実行し、トレーニング中に観測を解釈できるようにする。
* これにより、AI がより堅牢になります。

このボーナスユニットはオプションであり、ユニット 1 よりも高度です。

このボーナスユニットでは次のことを学びます。

* 関数呼び出し
* LoRA (Low-Rank Adaptation)
* 関数呼び出しモデルにおける思考 → 行動 → 観察サイクル
* 新しい特殊トークン

このボーナスユニットの完了までに、次のことができるようになります。

* ツールとの API の内部動作を理解する。
* LoRA テクニックを使用してモデルを微調整する。
* 堅牢で保守可能な関数呼び出しワークフローを作成するために思考 → 行動 → 観察サイクルを実装および変更する。
* モデルの内部的な推論と外部的な行動をシームレスに区別するために特殊トークンを設計して利用する。
* 関数呼び出しを行うように独自のモデルを微調整する。

## What is Function Calling?
### How does the model "learn" to take an action?
### 要約
関数呼び出しは、LLM（大規模言語モデル）が外部環境と対話するための手段です。GPT-4 で初めて導入され、他のモデルにも取り入れられました。エージェントのツールのように、関数呼び出しはモデルに環境への働きかけを可能にします。ただし、関数呼び出し能力はモデルによって学習され、他のエージェント技術よりもプロンプトへの依存度が低いです。

ユニット1のエージェントでは、ツールを使うことを学習させずにツールリストを提供し、モデルがそれらを使って計画を立てる能力を一般化できることに依存していました。一方、関数呼び出しでは、エージェントはツールを使用するようにファインチューニング（訓練）されます。

モデルはどのように行動を「学習」するのでしょうか？ユニット1では、エージェントの一般的なワークフローを調べました。ユーザーがエージェントにツールを提供し、クエリでプロンプトすると、モデルは次のサイクルを繰り返します。

* **思考:** 目的を達成するためにはどのような行動をとる必要があるか？
* **行動:** 正しいパラメータで行動をフォーマットし、生成を停止する。
* **観察:** 実行結果を取得する。

通常のAPIを介したモデルとの会話では、ユーザーとアシスタントのメッセージが交互にやり取りされます。関数呼び出しはこの会話に新しい役割をもたらします。行動と観察それぞれに新しい役割が追加されます。

多くのAPIでは、モデルは取るべき行動を「アシスタント」メッセージとしてフォーマットします。チャットテンプレートは、これを関数呼び出しのための特別なトークンとして表現します。

このコースでは、関数呼び出しについて再び説明しますが、より深く理解したい場合は、関連ドキュメントを参照してください。関数呼び出しの仕組みを理解した上で、関数呼び出し機能を持たないモデル「google/gemma-2-2b-it」に、新しい特別なトークンを追加することで関数呼び出し機能を追加します。そのためには、まずファインチューニングとLoRAを理解する必要があります。

## Let’s Fine-Tune your model for function-calling
### 要約
この文章は、関数呼び出しに対応した大規模言語モデルのファインチューニング方法について説明しています。

主なポイントは３つです。

1. **モデルの訓練段階:**  まず大規模データで事前学習されたベースモデル（例: google/gemma-2-2b）を用意します。次に、指示に従うようファインチューニングされたモデル（例: google/gemma-2-2b-it）を利用するのが効率的です。最後に、関数呼び出しのための追加のファインチューニングを行います。

2. **LoRAを用いた効率的なファインチューニング:**  LoRA (Low-Rank Adaptation)という手法を用いることで、訓練に必要なパラメータ数を大幅に削減し、メモリ効率の良い、高速なファインチューニングを実現します。

3. **チュートリアルへのリンク:**  関数呼び出しモデルのファインチューニング方法を学ぶためのチュートリアルノートブックへのリンクが提供されています。


要約すると、既存の指示追従済みモデルをベースに、LoRAを用いて効率的に関数呼び出し機能を追加するファインチューニング方法とそのチュートリアルを紹介している記事です。

### How do we train our model for function-calling ?
### 日本語訳
モデルのトレーニングは 3 つのステップに分けられます。

モデルは大量のデータで事前トレーニングされています。そのステップの出力は事前トレーニング済みモデルです。たとえば、google/gemma-2-2bです。これは基本モデルであり、適切な指示に従う能力がなく、次のトークンを予測する方法しか知りません。

モデルをチャットのコンテキストで役立てるには、指示に従うように微調整する必要があります。このステップでは、モデル作成者、オープンソース コミュニティ、あなた、または誰でもモデルをトレーニングできます。たとえば、google/gemma-2-2b-it は、 Gemma プロジェクトの背後にある Google チームによって指示調整されたモデルです。

その後、モデルは作成者の好みに合わせて調整できます。たとえば、顧客に対して失礼な態度を取ってはならないカスタマー サービス チャット モデルなどです。

通常、Gemini や Mistral のような完成品は3 つのステップすべてを経ますが、Hugging Face で見つかるモデルは、このトレーニングの 1 つ以上のステップに合格しています。

このチュートリアルでは、 google/gemma-2-2b-itに基づいて関数呼び出しモデルを構築します。ベースモデルはgoogle/gemma-2-2bであり、Google チームは次の手順に従ってベースモデルを微調整し、結果として「google/gemma-2-2b-it」が生まれました。

この場合、ベースモデルではなく「google/gemma-2-2b-it」をベースとして使用します。これは、ユースケースでは事前に行われた微調整が重要であるためです。

メッセージでの会話を通じてモデルと対話したいので、基本モデルから始めて、指示に従うこと、チャット、関数の呼び出しを学習するために、より多くのトレーニングが必要になります。

指示調整されたモデル(the instruct-tuned model)から開始することで、モデルが学習する必要がある情報の量を最小限に抑えます。

### LoRA  (Low-Rank Adaptation of Large Language Models)
### 日本語訳
LoRA (Low-Rank Adaptation of Large Language Models) は、トレーニング可能なパラメータの数を大幅に削減する、人気の軽量トレーニング手法です。

これは、トレーニングするモデルにアダプターとして少数の新しい重みを挿入することで機能します。これにより、LoRA を使用したトレーニングが大幅に高速化され、メモリ効率が向上し、モデルの重みが小さくなり (数百 MB)、保存と共有が容易になります。

LoRA は、Transformer レイヤーにランク分解行列のペアを追加することで機能し、通常は線形レイヤーに重点が置かれます。トレーニング中は、モデルの残りの部分を「フリーズ」し、新しく追加されたアダプターの重みのみを更新します。

そうすることで、アダプターの重みを更新するだけで済むため、トレーニングに必要なパラメータの数が大幅に減少します。

推論中、入力はアダプタとベース モデルに渡されるか、これらのアダプタの重みをベース モデルとマージできるため、追加のレイテンシ オーバーヘッドは発生しません。

LoRA は、リソース要件を管理可能な範囲に維持しながら、大規模な言語モデルを特定のタスクまたはドメインに適応させるのに特に役立ちます。これにより、モデルのトレーニングに必要なメモリを削減できます。

---

詳しくはこのチュートリアルをみてくれ -> https://huggingface.co/learn/nlp-course/chapter11/4?fw=pt

### Fine-Tuning a model for Function-calling
これはColab ノートブックを使ってやっていくらしい

## Conclusion
なるほど、これだけ？ファインチューニングについての簡単な説明のみであとはチュートリアルを楽しんでね！ってことかな

